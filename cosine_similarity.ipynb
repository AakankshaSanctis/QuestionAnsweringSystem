{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#from question_set import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aakanksha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/aakanksha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set of all stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a question :when was apollo 13 launched\n"
     ]
    }
   ],
   "source": [
    "q_corpus=pd.read_csv('questions.csv')\n",
    "test_q=input(\"Enter a question :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query preprocessing-Tokenization,removing stopwords and stemming\n",
    "def process_query(query):\n",
    "    tokens=word_tokenize(query)\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    tokens=[w for w in tokens if w not in stopwords]\n",
    "    tokens=[stemmer.stem(w) for w in tokens]\n",
    "    tokens=[w for w in tokens if w!='?']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate term frequency of the query doc\n",
    "def tf_value(q_entry):\n",
    "    tf_mat={}\n",
    "    terms=[]\n",
    "    terms=process_query(q_entry)\n",
    "    for t in terms:\n",
    "        if t in tf_mat:\n",
    "            tf_mat[t]+=1\n",
    "        else:\n",
    "            tf_mat[t]=1\n",
    "    return tf_mat\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apollo : 1 \n",
      "13 : 1 \n",
      "launch : 1 \n"
     ]
    }
   ],
   "source": [
    "#test_q='Where was Beyonce Knowles born?'\n",
    "tf_q=tf_value(test_q)\n",
    "for t in tf_q:\n",
    "    print(\"%s : %d \"%(t,tf_q[t]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the idf of each term\n",
    "\n",
    "def idf_value(q_entry,q_data):\n",
    "    \n",
    "    org_q=process_query(q_entry)#process the query\n",
    "    \n",
    "    idf_dict={}\n",
    "    #Make dictionary containing doc freq of each term in query\n",
    "    for t in org_q:\n",
    "        idf_dict[t]=0\n",
    "   \n",
    "    #Check for every question_doc if it contains the term\n",
    "    questions=q_data['Question']\n",
    "    for q in questions:\n",
    "        proc_q=process_query(q)\n",
    "        for t in org_q:\n",
    "            if t in proc_q:\n",
    "                idf_dict[t]+=1\n",
    "    for t in idf_dict:\n",
    "        if idf_dict[t]>0:\n",
    "            idf_dict[t]=math.log10(len(q_data)/float(idf_dict[t]))\n",
    "        \n",
    "    \n",
    "    return idf_dict\n",
    "             \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the test question tf-idf vector\n",
    "def test_tf_idf_vector(test_q,q_corpus):\n",
    "    \n",
    "    tf_q=tf_value(test_q)\n",
    "    idf_q=idf_value(test_q,q_corpus)\n",
    "    \n",
    "    tf_idf_wt={}\n",
    "    tf_wt={}\n",
    "    for t in tf_q:\n",
    "        tf_wt[t]=1+math.log10(tf_q[t])\n",
    "        tf_idf_wt[t]=tf_wt[t]*idf_q[t]\n",
    "    \n",
    "    norm=0\n",
    "    for t in tf_idf_wt:\n",
    "        norm=norm+pow(tf_idf_wt[t],2)\n",
    "    norm=math.sqrt(norm)\n",
    "    \n",
    "    for t in tf_idf_wt:\n",
    "        tf_idf_wt[t]=tf_idf_wt[t]/(float(norm))\n",
    "        \n",
    "    return tf_idf_wt\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the tf-idf weight matrix for all the documents\n",
    "def doc_tf_idf_vector(q_corpus):\n",
    "    tf_docs={}\n",
    "    \n",
    "    for i in range(len(q_corpus)):\n",
    "        tf_docs[q_corpus['QuestionID'][i]]=tf_value(q_corpus['Question'][i])\n",
    "        \n",
    "   # tf_wt={}\n",
    "    tf_idf_wt={}\n",
    "    \n",
    "    for i in range(len(q_corpus)):\n",
    "        tf_wt={}\n",
    "        tf=tf_docs[q_corpus['QuestionID'][i]]\n",
    "        idf=idf_value(q_corpus['Question'][i],q_corpus)\n",
    "        \n",
    "        #question=q_corpus['Question'][i]\n",
    "        #question=process_query(question)\n",
    "        for t in tf:\n",
    "            tf_wt[t]=1+math.log10(tf[t])\n",
    "            tf_wt[t]=tf_wt[t]*idf[t]\n",
    "            \n",
    "        norm=0\n",
    "        for t in tf_wt:\n",
    "            norm=norm+pow(tf_wt[t],2)\n",
    "        norm=math.sqrt(norm)\n",
    "        for t in tf_wt:\n",
    "            tf_wt[t]=tf_wt[t]/(float(norm))\n",
    "            \n",
    "        tf_idf_wt[q_corpus['QuestionID'][i]]=tf_wt\n",
    "    return tf_idf_wt\n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the cosine similarity\n",
    "\n",
    "def cosine_sim(q_corpus,test_q):\n",
    "    \n",
    "    query_vect=test_tf_idf_vector(test_q,q_corpus)\n",
    "    question_doc_vector=doc_tf_idf_vector(q_corpus)\n",
    "    \n",
    "    max_cosine=0\n",
    "    max_cos_qid=0\n",
    "    \n",
    "    for q in question_doc_vector:\n",
    "        q_vector=question_doc_vector[q]\n",
    "        \n",
    "        #common=set(q_vector) & set(query_vect)\n",
    "        \n",
    "        cosine=0\n",
    "        for w in q_vector:\n",
    "            if w in query_vector:\n",
    "                cosine=cosine+q_vector[w]*query_vector[w]\n",
    "        #print(cosine)\n",
    "        if cosine>max_cosine:\n",
    "            max_cosine=cosine\n",
    "            max_cos_qid=q\n",
    "    return max_cos_qid\n",
    "      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5\n"
     ]
    }
   ],
   "source": [
    "qid=cosine_sim(q_corpus,test_q)\n",
    "print(qid)\n",
    "#query_vector=test_tf_idf_vector(test_q,q_corpus)\n",
    "#doc_vector=doc_tf_idf_vector(q_corpus)\n",
    "\n",
    "#print(query_vector)\n",
    "#print(doc_vector)\n",
    "#tf_q=tf_value(test_q)\n",
    "#for q in tf_q:\n",
    "#    print(\"%s : %d \"%(q,tf_q[q]))\n",
    "#idf_q=idf_value(test_q,q_corpus)\n",
    "#for q in idf_q:\n",
    "#    print(\"%s : %d \"%(q,idf_q[q]) )\n",
    "\n",
    "#q_set=q_corpus.head()\n",
    "#qid=cosine_sim(q_set,test_q)\n",
    "#print(qid)\n",
    "#q_corpus['Question']\n",
    "#q_corpus['QuestionID'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
